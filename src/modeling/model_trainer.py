"""
Module hu·∫•n luy·ªán m√¥ h√¨nh h·ªçc m√°y cho d·ª± √°n Taxi Price Prediction.

Class ModelTrainer cung c·∫•p c√°c ch·ª©c nƒÉng:
- N·∫°p v√† chia d·ªØ li·ªáu
- Hu·∫•n luy·ªán nhi·ªÅu m√¥ h√¨nh (Polynomial Regression, Random Forest, XGBoost)
- T·ªëi ∆∞u hyperparameters b·∫±ng Optuna
- ƒê√°nh gi√° v√† so s√°nh m√¥ h√¨nh
- L∆∞u/t·∫£i m√¥ h√¨nh
- Tr·ª±c quan h√≥a k·∫øt qu·∫£
"""

import logging
import json
import pickle
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any

import numpy as np
import pandas as pd
import joblib

from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score
from sklearn.preprocessing import PolynomialFeatures, StandardScaler
from sklearn.linear_model import LinearRegression, Ridge
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error

import xgboost as xgb
import optuna
from optuna.pruners import MedianPruner
from optuna.samplers import TPESampler

from src.visualization import DataVisualizer
from config import MODEL_RESULTS_DIR, MODELS_DIR, PLOT_DPI, PLOT_STYLE, FIGURE_SIZE


# C·∫•u h√¨nh logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class ModelTrainer:
    """
    L·ªõp x√¢y d·ª±ng, hu·∫•n luy·ªán v√† t·ªëi ∆∞u c√°c m√¥ h√¨nh h·ªçc m√°y cho b√†i to√°n Regression.
    
    H·ªó tr·ª£:
    - 3 m√¥ h√¨nh: Polynomial Regression, XGBoost, Random Forest
    - T·ªëi ∆∞u hyperparameters b·∫±ng Optuna
    - Logging qu√° tr√¨nh hu·∫•n luy·ªán
    - L∆∞u/t·∫£i m√¥ h√¨nh
    - ƒê√°nh gi√° k·∫øt qu·∫£ (RMSE, MAE, R¬≤)
    
    Attributes:
        X_train, X_test: Features c·ªßa train/test
        y_train, y_test: Target c·ªßa train/test
        models: Dictionary l∆∞u c√°c m√¥ h√¨nh ƒë√£ train
        best_model: M√¥ h√¨nh t·ªët nh·∫•t
        results: L∆∞u k·∫øt qu·∫£ ƒë√°nh gi√°
    """
    
    RANDOM_SEED = 42
    
    def __init__(self, 
                 X_train: pd.DataFrame, 
                 X_test: pd.DataFrame,
                 y_train: pd.Series,
                 y_test: pd.Series,
                 output_dir: str = "./models"):
        """
        Kh·ªüi t·∫°o ModelTrainer.
        
        Args:
            X_train, X_test: Features (ƒê√É SCALED t·ª´ preprocessing)
            y_train, y_test: Target
            output_dir: Th∆∞ m·ª•c l∆∞u k·∫øt qu·∫£
        """
        self.X_train = X_train.copy()
        self.X_test = X_test.copy()
        self.y_train = y_train.copy()
        self.y_test = y_test.copy()
        
        self.output_dir = Path(output_dir) if output_dir else MODELS_DIR
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        self.models = {}
        self.X_train_transformed = {}  # L∆∞u X_train ƒë√£ transform (cho Polynomial)
        self.X_test_transformed = {}   # L∆∞u X_test ƒë√£ transform (cho Polynomial)
        self.best_model = None
        self.best_model_name = None
        self.results = {}
        self.optimization_history = {}
        self.visualizer = DataVisualizer(
            output_dir=MODEL_RESULTS_DIR,
            auto_save=True,
            auto_show=False,
            dpi=PLOT_DPI,
            style=PLOT_STYLE,
            figure_size=FIGURE_SIZE,
        )
        
        # Set random seed ƒë·ªÉ reproducibility
        np.random.seed(self.RANDOM_SEED)
        
        logger.info(f"‚úÖ ModelTrainer kh·ªüi t·∫°o th√†nh c√¥ng")
        logger.info(f"   Train: {self.X_train.shape}, Test: {self.X_test.shape}")
    
    @property
    def data_info(self) -> Dict[str, Any]:
        """Tr·∫£ v·ªÅ th√¥ng tin d·ªØ li·ªáu."""
        return {
            'train_shape': self.X_train.shape,
            'test_shape': self.X_test.shape,
            'n_features': self.X_train.shape[1],
            'n_samples_train': self.X_train.shape[0],
            'n_samples_test': self.X_test.shape[0]
        }
    
    # ========== POLYNOMIAL REGRESSION ==========
    def _objective_polynomial(self, trial: optuna.Trial) -> float:
        """Objective function cho Polynomial Regression optimization."""
        degree = trial.suggest_int('degree', 2, 5)
        alpha = trial.suggest_float('alpha', 1e-3, 10, log=True)
        
        pipeline = Pipeline([
            ('poly', PolynomialFeatures(degree=degree, include_bias=False)),
            ('scaler', StandardScaler()),
            ('regressor', Ridge(alpha=alpha))
        ])
        
        cv_scores = cross_val_score(
            pipeline,
            self.X_train,
            self.y_train,
            cv=5,
            scoring='neg_mean_squared_error',
            n_jobs=-1
        )
        rmse = np.sqrt(-cv_scores.mean())
        return rmse
    
    def optimize_polynomial(self, n_trials: int = 10, timeout: int = 300) -> Dict:
        logger.info(f"\n{'='*70}")
        logger.info("üîç T·ªëi ∆∞u POLYNOMIAL REGRESSION b·∫±ng Optuna")
        logger.info(f"{'='*70}")
        
        sampler = TPESampler(seed=self.RANDOM_SEED)
        pruner = MedianPruner()
        
        study = optuna.create_study(
            sampler=sampler,
            pruner=pruner,
            direction='minimize'
        )
        study.optimize(
            self._objective_polynomial,
            n_trials=n_trials,
            timeout=timeout,
            show_progress_bar=True
        )
        
        best_params = study.best_params
        logger.info(f"‚úÖ Best params: {best_params}")
        logger.info(f"   Best RMSE: {study.best_value:.6f}")
        
        self.optimization_history['polynomial'] = {
            'best_params': best_params,
            'best_value': study.best_value,
            'n_trials': len(study.trials)
        }
        return best_params
    
    def train_polynomial(self, degree: int = 3, alpha: float = 1.0,
                         feature_subset: Optional[List[str]] = None) -> None:
        """Hu·∫•n luy·ªán Polynomial Regression v·ªõi scaling v√† Ridge regularization."""
        logger.info(f"\nüìä Training POLYNOMIAL REGRESSION (degree={degree}, alpha={alpha})")
        if feature_subset:
            valid_features = [col for col in feature_subset if col in self.X_train.columns]
            missing = [col for col in feature_subset if col not in self.X_train.columns]
            if missing:
                logger.warning(f"‚ö†Ô∏è  C√°c feature kh√¥ng t·ªìn t·∫°i v√† s·∫Ω b·ªã b·ªè qua: {missing}")
            if not valid_features:
                logger.warning("‚ö†Ô∏è  Kh√¥ng c√≤n feature h·ª£p l·ªá sau khi l·ªçc. S·ª≠ d·ª•ng to√†n b·ªô features.")
                feature_subset = None
            else:
                feature_subset = valid_features
                logger.info(f"   S·ª≠ d·ª•ng {len(feature_subset)} feature c√≥ |corr| >= threshold")
                logger.info(f"   Features: {feature_subset}")
        
        base_X_train = self.X_train[feature_subset] if feature_subset else self.X_train
        base_X_test = self.X_test[feature_subset] if feature_subset else self.X_test
        
        poly = PolynomialFeatures(degree=degree, include_bias=False)
        X_train_poly = poly.fit_transform(base_X_train)
        X_test_poly = poly.transform(base_X_test)
        
        logger.info(f"   Original features: {self.X_train.shape[1]}")
        logger.info(f"   Polynomial features: {X_train_poly.shape[1]}")
        
        poly_scaler = StandardScaler()
        X_train_poly_scaled = poly_scaler.fit_transform(X_train_poly)
        X_test_poly_scaled = poly_scaler.transform(X_test_poly)
        logger.info("   ‚úÖ Polynomial features ƒë∆∞·ª£c scale (StandardScaler)")
        
        model = Ridge(alpha=alpha)
        model.fit(X_train_poly_scaled, self.y_train)
        
        y_pred_train = model.predict(X_train_poly_scaled)
        y_pred_test = model.predict(X_test_poly_scaled)
        
        train_rmse = np.sqrt(mean_squared_error(self.y_train, y_pred_train))
        test_rmse = np.sqrt(mean_squared_error(self.y_test, y_pred_test))
        test_mae = mean_absolute_error(self.y_test, y_pred_test)
        test_r2 = r2_score(self.y_test, y_pred_test)
        
        self.models['polynomial'] = {
            'model': model,
            'poly': poly,
            'poly_scaler': poly_scaler,
            'feature_subset': feature_subset
        }
        self.X_train_transformed['polynomial'] = X_train_poly_scaled
        self.X_test_transformed['polynomial'] = X_test_poly_scaled
        
        self.results['polynomial'] = {
            'train_rmse': float(train_rmse),
            'test_rmse': float(test_rmse),
            'test_mae': float(test_mae),
            'test_r2': float(test_r2),
            'hyperparams': {
                'degree': degree,
                'alpha': alpha,
                'feature_subset': feature_subset if feature_subset else 'all'
            }
        }
        
        logger.info(f"   Train RMSE: {train_rmse:.6f}")
        logger.info(f"   Test RMSE: {test_rmse:.6f}")
        logger.info(f"   Test MAE: {test_mae:.6f}")
        logger.info(f"   Test R¬≤: {test_r2:.6f}")
    
    # ========== RANDOM FOREST REGRESSION ==========
    def _objective_rf(self, trial: optuna.Trial) -> float:
        """Objective function cho Random Forest optimization."""
        n_estimators = trial.suggest_int('n_estimators', 50, 300)
        max_depth = trial.suggest_int('max_depth', 5, 20)
        min_samples_split = trial.suggest_int('min_samples_split', 2, 10)
        min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 5)
        
        model = RandomForestRegressor(
            n_estimators=n_estimators,
            max_depth=max_depth,
            min_samples_split=min_samples_split,
            min_samples_leaf=min_samples_leaf,
            random_state=self.RANDOM_SEED,
            n_jobs=-1
        )
        
        # D√πng cross-validation TR√äN TRAIN SET (kh√¥ng d√πng test set!)
        from sklearn.model_selection import cross_val_score
        cv_scores = cross_val_score(
            model, self.X_train, self.y_train,
            cv=5,
            scoring='neg_mean_squared_error',
            n_jobs=-1
        )
        rmse = np.sqrt(-cv_scores.mean())
        
        return rmse
    
    def optimize_rf(self, n_trials: int = 20, timeout: int = 600) -> Dict:
        """
        T·ªëi ∆∞u hyperparameters cho Random Forest.
        
        Args:
            n_trials: S·ªë l·∫ßn th·ª≠
            timeout: Timeout t√≠nh b·∫±ng gi√¢y
            
        Returns:
            Dictionary ch·ª©a best params
        """
        logger.info(f"\n{'='*70}")
        logger.info("üîç T·ªëi ∆∞u RANDOM FOREST b·∫±ng Optuna")
        logger.info(f"{'='*70}")
        
        sampler = TPESampler(seed=self.RANDOM_SEED)
        pruner = MedianPruner()
        
        study = optuna.create_study(
            sampler=sampler,
            pruner=pruner,
            direction='minimize'
        )
        
        study.optimize(
            self._objective_rf,
            n_trials=n_trials,
            timeout=timeout,
            show_progress_bar=True
        )
        
        best_params = study.best_params
        logger.info(f"‚úÖ Best params: {best_params}")
        logger.info(f"   Best RMSE: {study.best_value:.6f}")
        
        self.optimization_history['random_forest'] = {
            'best_params': best_params,
            'best_value': study.best_value,
            'n_trials': len(study.trials)
        }
        
        return best_params
    
    def train_rf(self, 
                 n_estimators: int = 100,
                 max_depth: int = 10,
                 min_samples_split: int = 5,
                 min_samples_leaf: int = 2) -> None:
        """Hu·∫•n luy·ªán Random Forest."""
        logger.info(f"\nüìä Training RANDOM FOREST")
        logger.info(f"   n_estimators={n_estimators}, max_depth={max_depth}")
        
        model = RandomForestRegressor(
            n_estimators=n_estimators,
            max_depth=max_depth,
            min_samples_split=min_samples_split,
            min_samples_leaf=min_samples_leaf,
            random_state=self.RANDOM_SEED,
            n_jobs=-1
        )
        
        # Tree-based model KH√îNG C·∫¶N scale
        model.fit(self.X_train, self.y_train)
        
        # ƒê√°nh gi√°
        y_pred_train = model.predict(self.X_train)
        y_pred_test = model.predict(self.X_test)
        
        train_rmse = np.sqrt(mean_squared_error(self.y_train, y_pred_train))
        test_rmse = np.sqrt(mean_squared_error(self.y_test, y_pred_test))
        test_mae = mean_absolute_error(self.y_test, y_pred_test)
        test_r2 = r2_score(self.y_test, y_pred_test)
        
        # L∆∞u model
        self.models['random_forest'] = {'model': model}
        self.results['random_forest'] = {
            'train_rmse': train_rmse,
            'test_rmse': test_rmse,
            'test_mae': test_mae,
            'test_r2': test_r2,
            'hyperparams': {
                'n_estimators': n_estimators,
                'max_depth': max_depth,
                'min_samples_split': min_samples_split,
                'min_samples_leaf': min_samples_leaf
            }
        }
        
        logger.info(f"   Train RMSE: {train_rmse:.6f}")
        logger.info(f"   Test RMSE: {test_rmse:.6f}")
        logger.info(f"   Test MAE: {test_mae:.6f}")
        logger.info(f"   Test R¬≤: {test_r2:.6f}")
    
    # ========== XGBOOST REGRESSION ==========
    def _objective_xgb(self, trial: optuna.Trial) -> float:
        """Objective function cho XGBoost optimization."""
        params = {
            'max_depth': trial.suggest_int('max_depth', 3, 10),
            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),
            'n_estimators': trial.suggest_int('n_estimators', 50, 300),
            'subsample': trial.suggest_float('subsample', 0.5, 1.0),
            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),
            'min_child_weight': trial.suggest_int('min_child_weight', 1, 5),
            'lambda': trial.suggest_float('lambda', 0.0, 1.0),
            'alpha': trial.suggest_float('alpha', 0.0, 1.0),
            'random_state': self.RANDOM_SEED
        }
        
        model = xgb.XGBRegressor(**params)
        
        # D√πng cross-validation TR√äN TRAIN SET
        cv_scores = cross_val_score(
            model, self.X_train, self.y_train,
            cv=5,
            scoring='neg_mean_squared_error',
            n_jobs=-1
        )
        rmse = np.sqrt(-cv_scores.mean())
        
        return rmse
    
    def optimize_xgb(self, n_trials: int = 30, timeout: int = 900) -> Dict:
        """
        T·ªëi ∆∞u hyperparameters cho XGBoost.
        
        Args:
            n_trials: S·ªë l·∫ßn th·ª≠
            timeout: Timeout t√≠nh b·∫±ng gi√¢y
            
        Returns:
            Dictionary ch·ª©a best params
        """
        logger.info(f"\n{'='*70}")
        logger.info("üîç T·ªëi ∆∞u XGBOOST b·∫±ng Optuna")
        logger.info(f"{'='*70}")
        
        sampler = TPESampler(seed=self.RANDOM_SEED)
        pruner = MedianPruner()
        
        study = optuna.create_study(
            sampler=sampler,
            pruner=pruner,
            direction='minimize'
        )
        
        study.optimize(
            self._objective_xgb,
            n_trials=n_trials,
            timeout=timeout,
            show_progress_bar=True
        )
        
        best_params = study.best_params
        logger.info(f"‚úÖ Best params: {best_params}")
        logger.info(f"   Best RMSE: {study.best_value:.6f}")
        
        self.optimization_history['xgboost'] = {
            'best_params': best_params,
            'best_value': study.best_value,
            'n_trials': len(study.trials)
        }
        
        return best_params
    
    def train_xgb(self, **xgb_params) -> None:
        """
        Hu·∫•n luy·ªán XGBoost.
        
        Args:
            **xgb_params: XGBoost hyperparameters
        """
        logger.info(f"\nüìä Training XGBOOST")
        
        # Default params
        default_params = {
            'max_depth': 6,
            'learning_rate': 0.1,
            'n_estimators': 100,
            'subsample': 0.8,
            'colsample_bytree': 0.8,
            'random_state': self.RANDOM_SEED
        }
        
        # Update v·ªõi params ƒë∆∞·ª£c truy·ªÅn v√†o
        default_params.update(xgb_params)
        
        model = xgb.XGBRegressor(**default_params)
        
        # Tree-based kh√¥ng c·∫ßn scale
        model.fit(self.X_train, self.y_train, verbose=False)
        
        # ƒê√°nh gi√°
        y_pred_train = model.predict(self.X_train)
        y_pred_test = model.predict(self.X_test)
        
        train_rmse = np.sqrt(mean_squared_error(self.y_train, y_pred_train))
        test_rmse = np.sqrt(mean_squared_error(self.y_test, y_pred_test))
        test_mae = mean_absolute_error(self.y_test, y_pred_test)
        test_r2 = r2_score(self.y_test, y_pred_test)
        
        # L∆∞u model
        self.models['xgboost'] = {'model': model}
        self.results['xgboost'] = {
            'train_rmse': train_rmse,
            'test_rmse': test_rmse,
            'test_mae': test_mae,
            'test_r2': test_r2,
            'hyperparams': default_params
        }
        
        logger.info(f"   Train RMSE: {train_rmse:.6f}")
        logger.info(f"   Test RMSE: {test_rmse:.6f}")
        logger.info(f"   Test MAE: {test_mae:.6f}")
        logger.info(f"   Test R¬≤: {test_r2:.6f}")
    
    # ========== SAVE & LOAD MODELS ==========
    def save_model(self, model_name: str, format: str = 'joblib') -> str:
        """
        L∆∞u m√¥ h√¨nh v√†o file.
        
        Args:
            model_name: T√™n m√¥ h√¨nh ('polynomial', 'random_forest', 'xgboost')
            format: ƒê·ªãnh d·∫°ng ('joblib' ho·∫∑c 'pickle')
            
        Returns:
            ƒê∆∞·ªùng d·∫´n file
        """
        if model_name not in self.models:
            logger.error(f"‚ùå Kh√¥ng t√¨m th·∫•y m√¥ h√¨nh: {model_name}")
            return None
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = self.output_dir / f"{model_name}_{timestamp}.{format}"
        
        model_data = self.models[model_name]
        
        if format == 'joblib':
            joblib.dump(model_data, filename)
        elif format == 'pickle':
            with open(filename, 'wb') as f:
                pickle.dump(model_data, f)
        
        logger.info(f"‚úÖ ƒê√£ l∆∞u m√¥ h√¨nh: {filename}")
        return str(filename)
    
    def load_model(self, filepath: str, model_name: str) -> None:
        """
        T·∫£i m√¥ h√¨nh t·ª´ file.
        
        Args:
            filepath: ƒê∆∞·ªùng d·∫´n file
            model_name: T√™n m√¥ h√¨nh ƒë·ªÉ l∆∞u
        """
        filepath = Path(filepath)
        
        if filepath.suffix == '.joblib':
            model_data = joblib.load(filepath)
        else:
            with open(filepath, 'rb') as f:
                model_data = pickle.load(f)
        
        self.models[model_name] = model_data
        logger.info(f"‚úÖ ƒê√£ t·∫£i m√¥ h√¨nh: {filepath}")
    
    # ========== EVALUATION & COMPARISON ==========
    def get_best_model(self) -> Tuple[str, Dict]:
        """
        L·∫•y m√¥ h√¨nh t·ªët nh·∫•t d·ª±a tr√™n test R¬≤.
        
        Returns:
            (model_name, results)
        """
        best_r2 = -np.inf
        best_name = None
        
        for name, result in self.results.items():
            if result['test_r2'] > best_r2:
                best_r2 = result['test_r2']
                best_name = name
        
        self.best_model_name = best_name
        if best_name:
            self.best_model = self.models[best_name]['model']
        
        return best_name, self.results[best_name] if best_name else None
    
    def save_results(self, filename: str = 'model_results.json') -> None:
        """L∆∞u k·∫øt qu·∫£ ƒë√°nh gi√° ra file JSON."""
        filepath = MODEL_RESULTS_DIR / filename
        filepath.parent.mkdir(parents=True, exist_ok=True)
        
        # Convert np types sang Python types
        results_serializable = {}
        for model_name, result in self.results.items():
            results_serializable[model_name] = {
                'train_rmse': float(result['train_rmse']),
                'test_rmse': float(result['test_rmse']),
                'test_mae': float(result['test_mae']),
                'test_r2': float(result['test_r2']),
                'hyperparams': result['hyperparams']
            }
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(results_serializable, f, indent=4, ensure_ascii=False)
        
        logger.info(f"‚úÖ ƒê√£ l∆∞u k·∫øt qu·∫£: {filepath}")
    
    def plot_comparison(self, metric: str = 'test_r2', save: bool = True) -> None:
        """
        V·∫Ω bi·ªÉu ƒë·ªì so s√°nh c√°c m√¥ h√¨nh.
        
        Args:
            metric: Metric ƒë·ªÉ so s√°nh ('test_r2', 'test_rmse', 'test_mae')
            save: C√≥ l∆∞u bi·ªÉu ƒë·ªì kh√¥ng
        """
        if not self.results:
            logger.warning("‚ùå Ch∆∞a c√≥ k·∫øt qu·∫£ ƒë·ªÉ v·∫Ω bi·ªÉu ƒë·ªì")
            return
        
        metric_values = {model: self.results[model][metric] for model in self.results}
        if not metric_values:
            logger.warning("‚ùå Kh√¥ng c√≥ k·∫øt qu·∫£ ƒë·ªÉ v·∫Ω bi·ªÉu ƒë·ªì")
            return

        save_path = None
        if save:
            save_path = MODEL_RESULTS_DIR / f'comparison_{metric}.png'
        self.visualizer.plot_model_comparison(metric_values, metric, save_path=save_path, show=not save)
    
    def plot_predictions(self, model_name: str, save: bool = True) -> None:
        """V·∫Ω bi·ªÉu ƒë·ªì actual vs predicted."""
        if model_name not in self.models:
            logger.error(f"‚ùå Kh√¥ng t√¨m th·∫•y m√¥ h√¨nh: {model_name}")
            return
        
        model_obj = self.models[model_name]['model']
        
        # X·ª≠ l√Ω ƒë·∫∑c bi·ªát cho Polynomial (ƒë√£ ƒë∆∞·ª£c scaled)
        if model_name == 'polynomial':
            X_test_pred = self.X_test_transformed['polynomial']
        else:
            # RF v√† XGBoost d√πng raw data
            X_test_pred = self.X_test
        
        y_pred = model_obj.predict(X_test_pred)
        
        save_path = None
        if save:
            save_path = MODEL_RESULTS_DIR / f'predictions_{model_name}.png'
        self.visualizer.plot_regression_diagnostics(
            y_true=self.y_test,
            y_pred=y_pred,
            model_name=model_name,
            save_path=save_path,
            show=not save,
        )
    
    def plot_all_predictions(self, save: bool = True) -> None:
        """V·∫Ω bi·ªÉu ƒë·ªì predictions cho t·∫•t c·∫£ c√°c m√¥ h√¨nh."""
        logger.info(f"\n{'='*70}")
        logger.info("üìà V·∫º BI·ªÇU ƒê·ªí PREDICTIONS CHO T·∫§T C·∫¢ M√î H√åNH")
        logger.info(f"{'='*70}\n")
        
        for model_name in self.models.keys():
            self.plot_predictions(model_name, save=save)
    
    def summary(self) -> None:
        """In ra t√≥m t·∫Øt k·∫øt qu·∫£ c√°c m√¥ h√¨nh."""
        logger.info(f"\n{'='*70}")
        logger.info("üìä T√ìM T·∫ÆT K·∫æT QU·∫¢ TRAINING")
        logger.info(f"{'='*70}\n")
        
        summary_data = []
        for model_name, result in self.results.items():
            summary_data.append({
                'Model': model_name.upper(),
                'Train RMSE': f"{result['train_rmse']:.6f}",
                'Test RMSE': f"{result['test_rmse']:.6f}",
                'Test MAE': f"{result['test_mae']:.6f}",
                'Test R¬≤': f"{result['test_r2']:.6f}"
            })
        
        summary_df = pd.DataFrame(summary_data)
        print(summary_df.to_string(index=False))
        
        best_name, best_result = self.get_best_model()
        if best_name:
            logger.info(f"\n‚ú® M√î H√åNH T·ªêT NH·∫§T: {best_name.upper()}")
            logger.info(f"   Test R¬≤: {best_result['test_r2']:.6f}")
        
        logger.info(f"\n{'='*70}\n")
    
    # ========== DATA PREPARATION ==========
    @staticmethod
    def prepare_data(df: pd.DataFrame, 
                     target_col: str = 'Trip_Price',
                     test_size: float = 0.2,
                     random_state: int = 42,
                     scale: bool = False) -> Tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series]:
        """
        Chia d·ªØ li·ªáu (KH√îNG scale - scale ƒë∆∞·ª£c th·ª±c hi·ªán ·ªü preprocessing).
        
        Args:
            df: DataFrame ch·ª©a d·ªØ li·ªáu
            target_col: T√™n c·ªôt target
            test_size: T·ª∑ l·ªá test set
            random_state: Random seed
            scale: DEPRECATED - Kh√¥ng n√™n scale ·ªü ƒë√¢y, scale ·ªü preprocessing
            
        Returns:
            (X_train, X_test, y_train, y_test)
        """
        logger.info(f"\n{'='*70}")
        logger.info("üîÑ CHU·∫®N B·ªä D·ªÆ LI·ªÜU CHO TRAINING")
        logger.info(f"{'='*70}")
        
        # T√°ch Features v√† Target
        X = df.drop(target_col, axis=1)
        y = df[target_col]
        
        logger.info(f"Total samples: {len(df)}, Features: {X.shape[1]}")
        
        # Chia Train/Test
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size, random_state=random_state
        )
        
        logger.info(f"Train set: {X_train.shape[0]}, Test set: {X_test.shape[0]}")
        
        # Scale d·ªØ li·ªáu n·∫øu c·∫ßn (KH√îNG khuy·∫øn ngh·ªã)
        if scale:
            logger.warning("‚ö†Ô∏è  scale=True kh√¥ng khuy·∫øn ngh·ªã - N√™n scale ·ªü preprocessing!")
            scaler = StandardScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            X_test_scaled = scaler.transform(X_test)
            
            # Chuy·ªÉn th√†nh DataFrame
            X_train = pd.DataFrame(X_train_scaled, columns=X.columns)
            X_test = pd.DataFrame(X_test_scaled, columns=X.columns)
            
            logger.info(f"‚úÖ D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c chu·∫©n h√≥a (StandardScaler)")
        
        logger.info(f"   X_train shape: {X_train.shape}")
        logger.info(f"   X_test shape: {X_test.shape}\n")
        
        return X_train, X_test, y_train, y_test
    
    # ========== SAVE ALL MODELS ==========
    def save_all_models(self, format: str = 'joblib') -> None:
        """
        L∆∞u t·∫•t c·∫£ c√°c m√¥ h√¨nh ƒë√£ train.
        
        Args:
            format: ƒê·ªãnh d·∫°ng ('joblib' ho·∫∑c 'pickle')
        """
        logger.info(f"\n{'='*70}")
        logger.info("üíæ L∆ØU T·∫§T C·∫¢ C√ÅC M√î H√åNH")
        logger.info(f"{'='*70}")
        
        for model_name in self.models.keys():
            self.save_model(model_name, format=format)
        
        logger.info(f"\n‚úÖ Ho√†n t·∫•t l∆∞u {len(self.models)} m√¥ h√¨nh!\n")
    
    def predict(self, X: pd.DataFrame, model_name: Optional[str] = None) -> np.ndarray:
        """
        D·ª± ƒëo√°n v·ªõi m√¥ h√¨nh ƒë√£ train.
        
        Args:
            X: Features c·∫ßn d·ª± ƒëo√°n
            model_name: T√™n m√¥ h√¨nh (None = d√πng best model)
            
        Returns:
            Array predictions
        """
        if model_name is None:
            if self.best_model_name is None:
                self.get_best_model()
            model_name = self.best_model_name
        
        if model_name not in self.models:
            raise ValueError(f"M√¥ h√¨nh {model_name} ch∆∞a ƒë∆∞·ª£c train")
        
        model_obj = self.models[model_name]['model']
        
        # X·ª≠ l√Ω cho Polynomial (c·∫ßn transform + scale)
        if model_name == 'polynomial':
            poly = self.models[model_name]['poly']
            poly_scaler = self.models[model_name]['poly_scaler']
            feature_subset = self.models[model_name].get('feature_subset')
            X_input = X[feature_subset] if feature_subset else X
            X_poly = poly.transform(X_input)
            X_poly = poly_scaler.transform(X_poly)
            return model_obj.predict(X_poly)
        
        # C√°c model kh√°c d√πng X tr·ª±c ti·∫øp (ƒë√£ scaled t·ª´ preprocessing)
        return model_obj.predict(X)
    
    # ========== FEATURE IMPORTANCE ==========
    def get_feature_importance(self, model_name: str, top_n: int = 10) -> pd.DataFrame:
        """
        L·∫•y feature importance c·ªßa m√¥ h√¨nh.
        
        Args:
            model_name: T√™n m√¥ h√¨nh ('random_forest', 'xgboost')
            top_n: S·ªë l∆∞·ª£ng features quan tr·ªçng nh·∫•t
            
        Returns:
            DataFrame ch·ª©a feature importance
        """
        if model_name not in self.models:
            logger.error(f"‚ùå M√¥ h√¨nh {model_name} ch∆∞a ƒë∆∞·ª£c train")
            return None
        
        if model_name == 'polynomial':
            logger.warning("‚ö†Ô∏è  Polynomial Regression kh√¥ng h·ªó tr·ª£ feature importance")
            return None
        
        model_obj = self.models[model_name]['model']
        
        # L·∫•y feature importance
        if hasattr(model_obj, 'feature_importances_'):
            importances = model_obj.feature_importances_
            feature_names = self.X_train.columns
            
            # T·∫°o DataFrame
            importance_df = pd.DataFrame({
                'feature': feature_names,
                'importance': importances
            }).sort_values('importance', ascending=False).head(top_n)
            
            return importance_df
        else:
            logger.warning(f"‚ö†Ô∏è  M√¥ h√¨nh {model_name} kh√¥ng h·ªó tr·ª£ feature importance")
            return None
    
    def plot_feature_importance(self, model_name: str, top_n: int = 15, save: bool = True) -> None:
        """
        V·∫Ω bi·ªÉu ƒë·ªì feature importance.
        
        Args:
            model_name: T√™n m√¥ h√¨nh
            top_n: S·ªë l∆∞·ª£ng features hi·ªÉn th·ªã
            save: C√≥ l∆∞u bi·ªÉu ƒë·ªì kh√¥ng
        """
        importance_df = self.get_feature_importance(model_name, top_n=top_n)
        
        if importance_df is None:
            return
        
        logger.info(f"\nüìä Feature Importance - {model_name.upper()}")
        logger.info(f"{'='*70}")
        print(importance_df.to_string(index=False))
        
        # V·∫Ω bi·ªÉu ƒë·ªì
        save_path = None
        if save:
            save_path = MODEL_RESULTS_DIR / f'feature_importance_{model_name}.png'
        self.visualizer.plot_feature_importance(
            importance_df=importance_df,
            model_name=model_name,
            save_path=save_path,
            top_n=top_n,
            show=not save,
        )
    
    def plot_all_feature_importance(self, top_n: int = 15, save: bool = True) -> None:
        """V·∫Ω feature importance cho t·∫•t c·∫£ m√¥ h√¨nh h·ªó tr·ª£ (b·ªè qua Polynomial)."""
        logger.info(f"\n{'='*70}")
        logger.info("üìä V·∫º FEATURE IMPORTANCE CHO T·∫§T C·∫¢ M√î H√åNH")
        logger.info(f"{'='*70}\n")
        
        # L·ªçc c√°c models h·ªó tr·ª£ feature importance
        supported_models = [m for m in self.models.keys() if m != 'polynomial']
        
        if not supported_models:
            logger.warning("‚ö†Ô∏è  Kh√¥ng c√≥ m√¥ h√¨nh n√†o h·ªó tr·ª£ feature importance (ch·ªâ c√≥ Polynomial)")
            return
        
        for model_name in supported_models:
            self.plot_feature_importance(model_name, top_n=top_n, save=save)
    
    def compare_feature_importance(self, top_n: int = 10, save: bool = True) -> None:
        """
        So s√°nh feature importance gi·ªØa c√°c m√¥ h√¨nh (b·ªè qua Polynomial).
        
        Args:
            top_n: S·ªë features hi·ªÉn th·ªã
            save: C√≥ l∆∞u bi·ªÉu ƒë·ªì kh√¥ng
        """
        logger.info(f"\n{'='*70}")
        logger.info("üìä SO S√ÅNH FEATURE IMPORTANCE GI·ªÆA C√ÅC M√î H√åNH")
        logger.info(f"{'='*70}\n")
        
        # L·∫•y feature importance t·ª´ c√°c m√¥ h√¨nh (ch·ªâ RF v√† XGBoost)
        importances = {}
        for model_name in ['random_forest', 'xgboost']:
            if model_name in self.models:
                imp_df = self.get_feature_importance(model_name, top_n=top_n)
                if imp_df is not None:
                    importances[model_name] = imp_df
        
        if len(importances) == 0:
            logger.warning("‚ö†Ô∏è  Kh√¥ng c√≥ m√¥ h√¨nh n√†o h·ªó tr·ª£ feature importance ƒë·ªÉ so s√°nh")
            return
        
        if len(importances) == 1:
            logger.warning(f"‚ö†Ô∏è  Ch·ªâ c√≥ 1 m√¥ h√¨nh ({list(importances.keys())[0]}), c·∫ßn √≠t nh·∫•t 2 ƒë·ªÉ so s√°nh")
            logger.info(f"üí° S·ª≠ d·ª•ng plot_feature_importance('{list(importances.keys())[0]}') ƒë·ªÉ v·∫Ω ri√™ng")
            return
        
        # V·∫Ω bi·ªÉu ƒë·ªì so s√°nh
        save_path = None
        if save:
            save_path = MODEL_RESULTS_DIR / 'feature_importance_comparison.png'
        self.visualizer.plot_feature_importance_comparison(
            importances=importances,
            save_path=save_path,
            top_n=top_n,
            show=not save,
        )
